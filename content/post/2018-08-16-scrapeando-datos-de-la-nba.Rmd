---
title: Scraping NBA data
author: Rafa
date: '2018-08-16'
slug: scraping-nba-data
categories: []
tags: []
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```


The NBA does a great job releasing statistics on every aspect of the game. Most teams have analytics experts crunching those numbers for insights to get a competitive advantage.

In this post I go through the process of scraping data from [basketball-reference.com](https://www.basketball-reference.com/) using the R package `rvest`. We also do some data munging with `purrr` and string interpolation with `glue`.


# NBA Reference
This website has statistics on every aspect of the game for a long time. In this post, I'll focus on individual player stats (Field Goal Percentage, Average Minutes, etc.) from the 2000/2001 season up to 2017/2018.

If you follow [this link](https://www.basketball-reference.com/leagues/NBA_2017_per_game.html), you can find the data for the 2017 season in an html table.

Html uses a special markup language to format the tables so that your browser can render it properly. Typically, an html table has this structure:

# ```{html, eval = FALSE}
# <table>
#   <th>Player</th>
#   <td>Data<td>
# </table>
# ```

To get this into an R data frame, you can use rvest. The first step is to get all the html from the page using read_html.

```{r}
library(rvest)
nba_url <- "https://www.basketball-reference.com/leagues/NBA_2017_per_game.html"
web_page <- read_html(nba_url)
```

Now we need to get the actual data from the table. `html_table` does just that:

```{r}
data <- html_table(web_page)
str(data)
head(data[[1]])
```

That was easy! html_table returns a list with all the tables in the web_page as a data_frame. What we want is the first element of that list.

```{r}
data <- data[[1]]
```


Let's inspect the data:

```{r}
str(data)
```
Ok, so all the columns are read as text. That's natural, since all html pages are text, so we need to convert the data to the correct data types. So, most columns seem to be numeric, except Player Name which is a character, Player Position and  Team which are factors. One approach to correcting the data types is to use dplyr's mutate:

```{r, message=FALSE}
library(dplyr)
data_1 <- data %>% 
  mutate(Rk = as.numeric(Rk),
         Pos = as.factor(Pos),
         Age = as.numeric(Age))
#       ...

str(data_1)
```

But there's a better way:

```{r}
data_2 <- data %>% 
  mutate_at(vars(Tm, Pos), factor)

str(data_2)
```

`mutate_at` applies a function to a list of columns. The Columns need to be specified as a list of variables: `vars(Tm, Pos)`. In this case, the function applied is `factor`.

Now we do the same thing for the numeric variables using the `:` notation to select all the columns from G to PS.G.

```{r, eval = FALSE}
data_3 <- data %>% 
  mutate_at(vars(G:PS.G, Age), as.numeric)
str(data_3)
```

And now we have a data frame ready to use for analysis. But, what about the rest of the years? 



The first thing we need to do is build the url to get the html. We'll use a super cool package called `glue` for that. It does what programmer's call *string interpolation*:

```{r}
library(glue)
name <- "Rafa"
glue("Hello, {name}")
```

I'm sure you get the idea. 
  
    
You probably heard about the DRY principe: Don't repeat yourself. It'd be silly to write a whole script just to download data from another season, because most of the code would be the same. So we need to *reuse* our code to get data from the rest of the seasons.

For loops are used to *iterate* over collections, so we can repeat some process without copying the code. We can generate a vector with urls for every season we're interested in:
  
```{r}
base_url <- "https://www.basketball-reference.com/leagues/"
page <- "NBA_{year}_per_game.html"
urls <- vector("double", length(2000:2017))
for (year in 2000:2017) {
  urls[[year-1999]] <- glue(base_url, page) ## year -1999 gives 1, 2, 3, ...
}
head(urls)
```

Awesome! We can also iterate over the seasons and get the data we want. We now have to put the resulting data frames in a list instead of a vector.
  
```{r cache = TRUE}
base_url <- "https://www.basketball-reference.com/leagues/"
page <- "NBA_{year}_per_game.html"
data <- list()

for (year in 2015:2017) {
  nba_url <- glue(base_url, page) 
  web_page <- read_html(nba_url)
  data[[year-2014]] <- html_table(web_page)[[1]]

}
str(data)
```

# Better iteration with map
Ok, so now our script does everything we want it to do. But there's a wrinkle I'd like to iron out. A lot of programming is about iteration, and every programming language supports for loops.

But R has a great way to make iteration cleaner with the `purrr` package. There's a whole chapter on iteration in [R for Data Science](http://r4ds.had.co.nz/iteration.html), which is a must read for anyone interested in R.

We need to do the same thing for every year from 2000 to 2017. That's a job for `map`!

`map` takes a `list` and applies a function to every element of the list. Here, we apply the `head` function to a list of data frames to get the first 6 lines of each:
  
```{r}
my_list <- list(mtcars, iris)
purrr::map(my_list, head)
```
Instead of `head`, you can use your own function:
  
```{r}
my_list <- list(mtcars, iris)
my_func <- function(data_frame) { print("Hello from my fun!")}
purrr::map(my_list, my_func)
```

So now we need to figure out our initial list, and the function we want to apply to it's elements. The first part is easy:
  
```{r}
seasons <- as.list(2000:2017)
```

But now we need our script to fit into a function that takes one year and does the job for that year. Something like:
  
```{r}
get_player_data <- function(year) {
  base_url <- "https://www.basketball-reference.com/leagues/"
  page <- "NBA_{year}_per_game.html"
  # Download data
  nba_url <- glue(base_url, page) 
  # extract the data frame from the table
  web_page <- read_html(nba_url)
  data <- html_table(web_page)[[1]]
  # return a data frame
  data
}

data.14 <- get_player_data(2014)
head(data.14)
```

# Pipes
Pipes are a well known feature in the `tidyverse`, so I won't go into detail of how the work. We could turn our function into a set of pipes easily except for this line: `data <- html_table(web_page)[[1]]`. We need the name of the function, but what function are we calling in that line? We're actually calling two functions: `html_table` with the `we_page` argument and `[[` with `1` as an argument.

So we could do:
```{r}
web_page <- read_html(nba_url)
tbl_lst <- html_table(web_page)
df <- `[[`(tbl_lst, 1)
```
  
Or piping it like:
  
```{r}
df_2 <- web_page %>% 
 html_table %>% 
 `[[`(1)
```
We can re-write our get_player_data function as:
  
```{r}
get_player_data <- function(year) {
  base_url <- "https://www.basketball-reference.com/leagues/"
  page <- "NBA_{year}_per_game.html"
  
  glue(base_url, page) %>% 
    read_html %>% 
    html_table %>% 
    `[[`(1)
}

df.14 <- get_player_data(2014)
head(df.14)
```
Good, now we have everything we need for map:

```{r, cache = TRUE}
list_of_data_frames <- as.list(2015:2017) %>% 
  purrr::map(get_player_data)
  
str(list_of_data_frames)
```

# Another functional idiom: Reduce
Map takes list and returns a list. In our script, it takes a list of numbers as input and returns a list of data frames. We now need to roll all those data frames into a single data frame.

That's what reduce does. It takes a list and applies a function to consequtive pairs. accumulating the results. 
  
```{r}
lst <- list(1, 2, 3, 4) 
purrr::reduce(lst, sum) # don't do this in real life!
```
  
Of course, since R's sum is vectorized you don't ever need to do that,

Reduce works great with map:
  
```{r}
lst <- list(1, 2, 3, 4) 
# Find the sum of the square root of 1, 2, 3, 4
purrr::map(lst, sqrt) %>% 
  purrr::reduce(sum)
```

Another example: get the sum of the rows in a list of data frames:
```{r}
list(mtcars, iris) %>% 
  purrr::map(nrow) %>% 
  purrr::reduce(sum)
```

In our case, what we need it to use `reduce` with bind_rows, so we accumulate all the rows in our data_frame into a single one.

Ok, we're all set now, we put all our pieces together in the final script:
```{r script, eval = FALSE}
library(glue)
library(purrr)
library(dplyr)
library(rvest)

# Download data table from basketball reference
get_player_data <- function(year) {
  
  base_nba_url <- "https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html"
  
  glue(base_nba_url) %>% 
    read_html(nba_url) %>% 
    html_table() %>% 
    `[[`(1) %>% 
    mutate(Year = year)
}

data <- as.list(2000:2018) %>% 
  purrr::map(get_player_data) %>% 
  purrr::reduce(bind_rows)  %>% 
  mutate_at(vars(G:PS.G, Age), as.numeric) %>% 
  mutate_at(vars(Tm, Pos), factor) 

#saveRDS(data, file="nba_data_00_18.rds")
```